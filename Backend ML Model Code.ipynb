{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ADcRQapM6OQ",
        "outputId": "e14f89e5-113e-4d8c-b117-5e6adf5859c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.74)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT50hBRGQcO1",
        "outputId": "90eec566-ffbb-4f25-cdae-f10867744635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F46bOYpoUslP",
        "outputId": "9b686f8b-84e9-4150-d265-3fcbf3eb47f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing pytesseract library required to do OCR for text extraction from images\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-gJpW6qUyKV",
        "outputId": "25222b35-db64-4348-d648-88983d8a94de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "ww-qXmJiRCuq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import cv2\n",
        "# import pytesseract\n",
        "# import pandas as pd\n",
        "# from PIL import Image\n",
        "\n",
        "# def ocr_to_dataframe(image_path):\n",
        "#     # Load the image using OpenCV\n",
        "#     img = cv2.imread(image_path)\n",
        "\n",
        "#     # Perform OCR using Pytesseract\n",
        "#     text = pytesseract.image_to_string(Image.fromarray(img))\n",
        "\n",
        "#     # Split the text into lines\n",
        "#     lines = text.strip().split('\\n')\n",
        "\n",
        "#     # Create a DataFrame to store the extracted text\n",
        "#     df = pd.DataFrame({'Text': lines})\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # Example usage:\n",
        "# if __name__ == \"__main__\":\n",
        "#     image_path = '/content/Images Dataset/images'  # Replace with the path to your image\n",
        "#     df = ocr_to_dataframe(image_path)\n",
        "#     print(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "9c26YM_OTfp2"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import pytesseract\n",
        "# import pandas as pd\n",
        "# from PIL import Image\n",
        "# import os\n",
        "\n",
        "# def ocr_to_dataframe(image_paths):\n",
        "#     ocr_results = []\n",
        "#     for image_path in image_paths:\n",
        "#         if not os.path.isfile(image_path):\n",
        "#             print(f\"Error: File '{image_path}' not found.\")\n",
        "#             continue\n",
        "\n",
        "#         # Load the image using OpenCV\n",
        "#         img = cv2.imread(image_path)\n",
        "\n",
        "#         if img is None:\n",
        "#             print(f\"Error: Unable to read image '{image_path}'.\")\n",
        "#             continue\n",
        "\n",
        "#         # Perform OCR using Pytesseract\n",
        "#         text = pytesseract.image_to_string(Image.fromarray(img))\n",
        "\n",
        "#         # Split the text into lines\n",
        "#         lines = text.strip().split('\\n')\n",
        "\n",
        "#         # Store the OCR results in a DataFrame\n",
        "#         for line in lines:\n",
        "#             ocr_results.append({'Text': line, 'Image_Path': image_path})\n",
        "\n",
        "#     df = pd.DataFrame(ocr_results)\n",
        "#     return df\n",
        "\n",
        "# # Function to get image file paths from a folder\n",
        "# def get_image_paths_from_folder(folder_path):\n",
        "#     image_paths = []\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "#             image_paths.append(os.path.join(folder_path, filename))\n",
        "#     return image_paths\n",
        "\n",
        "# # Example usage:\n",
        "# if __name__ == \"__main__\":\n",
        "#     folder_path = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/images-dataset'  # Replace with the path to your image folder\n",
        "#     image_paths = get_image_paths_from_folder(folder_path)\n",
        "\n",
        "#     df = ocr_to_dataframe(image_paths)\n",
        "#     if df is not None and not df.empty:\n",
        "#         print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZtTGvXLEd8f",
        "outputId": "dfeddc63-411c-41d6-afcc-df08c2e38928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "DdWYOj7XEfV4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-geMXE7GEmMz",
        "outputId": "8da17716-923b-4d33-f92d-324144b60f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Jjxp1k1qEvvK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_text_from_images(image_folder):\n",
        "    text_data = []\n",
        "    image_paths = []  # Store the image paths instead of just names\n",
        "\n",
        "    for image_name in os.listdir(image_folder):\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "        img = cv2.imread(image_path,0)\n",
        "\n",
        "        ret,thresh1 = cv2.threshold(img,210,255,cv2.THRESH_BINARY)\n",
        "        blurred_image = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "        # gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise and smooth the image\n",
        "        # blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "\n",
        "    # Apply adaptive thresholding to create a binary image\n",
        "        threshold_image = cv2.adaptiveThreshold(\n",
        "        blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
        "        )\n",
        "\n",
        "        text = pytesseract.image_to_string(threshold_image)\n",
        "\n",
        "        # gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise and smooth the image\n",
        "        # blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "\n",
        "    # Apply adaptive thresholding to create a binary image\n",
        "\n",
        "\n",
        "        text_data.append(text)\n",
        "        image_paths.append(image_path)  # Store the image paths\n",
        "\n",
        "    return text_data, image_paths  # Return the image paths instead of names\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import pytesseract\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.svm import OneClassSVM\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# def preprocess_text_data(text_data):\n",
        "#     # Convert the text data to numerical features using TF-IDF vectorization\n",
        "#     vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "#     numerical_features = vectorizer.fit_transform(text_data)\n",
        "#     return numerical_features\n",
        "\n",
        "# image_folder = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/images-dataset'\n",
        "\n",
        "# # Extract text from images\n",
        "# text_data, image_paths = extract_text_from_images(image_folder)\n",
        "\n",
        "# # Create the DataFrame\n",
        "# df = pd.DataFrame({'Image Path': image_paths, 'Text Data': text_data})\n",
        "\n",
        "# # Step 1: Preprocess the data (if needed)\n",
        "\n",
        "# # Step 2: Convert the text data to numerical features\n",
        "# X = preprocess_text_data(df['Text Data'])\n",
        "\n",
        "# # Step 3: Train the One-Class SVM\n",
        "# one_class_svm = OneClassSVM(nu=0.1)  # You can adjust the hyperparameter nu\n",
        "# one_class_svm.fit(X)\n",
        "\n",
        "# # Step 4: Predict and Label the Data\n",
        "# predictions = one_class_svm.predict(X)\n",
        "# df['Label'] = np.where(predictions == 1, 'legitimate', 'fraud')"
      ],
      "metadata": {
        "id": "FdTTkV2dwx_L"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def preprocess_text_data(text_data):\n",
        "    # Convert the text data to numerical features using TF-IDF vectorization\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "    numerical_features = vectorizer.fit_transform(text_data)\n",
        "    return numerical_features\n",
        "\n",
        "image_folder = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/images-dataset'\n",
        "\n",
        "# Extract text from images\n",
        "text_data, image_paths = extract_text_from_images(image_folder)\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'Image Path': image_paths, 'Text Data': text_data})\n",
        "\n",
        "# Step 1: Preprocess the data (if needed)\n",
        "\n",
        "# Step 2: Convert the text data to numerical features\n",
        "X = preprocess_text_data(df['Text Data'])\n",
        "\n",
        "# Step 3: Train the One-Class SVM\n",
        "one_class_svm = OneClassSVM(nu=0.1)  # You can adjust the hyperparameter nu\n",
        "one_class_svm.fit(X)\n",
        "\n",
        "# Step 4: Predict and Label the Data\n",
        "predictions = one_class_svm.predict(X)\n",
        "df['Label'] = np.where(predictions == 1, 'legitimate', 'fraud')"
      ],
      "metadata": {
        "id": "R66U5F4J3NjL"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pktEi79LEz5C"
      },
      "outputs": [],
      "source": [
        "# image_folder = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/images-dataset'\n",
        "# text_data, image_paths = extract_text_from_images(image_folder)\n",
        "\n",
        "# df = pd.DataFrame({'Image Path': image_paths, 'Text Data': text_data})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "PnWnKRvYE4tU"
      },
      "outputs": [],
      "source": [
        "# isolation_forest = IsolationForest(contamination=0.1)\n",
        "# df['Label'] = isolation_forest.fit_predict(df['Text Data'].str.len().values.reshape(-1, 1))\n",
        "# df['Label'] = df['Label'].apply(lambda x: 'fraud' if x == -1 else 'legitimate')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "df['Text Data'] = df['Text Data'].str.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Handling missing values (if any)\n",
        "df.dropna(subset=['Text Data'], inplace=True)\n",
        "\n",
        "# Converting all text to lowercase\n",
        "df['Text Data'] = df['Text Data'].str.lower()\n",
        "\n",
        "# Removing duplicate rows (if any)\n",
        "df.drop_duplicates(subset=['Text Data'], inplace=True)\n",
        "\n",
        "# Convert 'Label' to numerical values (0 for 'fraud' and 1 for 'legitimate')\n",
        "df['Label'] = df['Label'].apply(lambda x: 1 if x == 'legitimate' else 0)"
      ],
      "metadata": {
        "id": "DL35lLM7w6Mw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import pytesseract\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from keras.models import Model\n",
        "# from keras.layers import Input, Dense\n",
        "\n",
        "# def extract_text_from_images(image_folder):\n",
        "#     text_data = []\n",
        "#     image_paths = []  # Store the image paths instead of just names\n",
        "\n",
        "#     for image_name in os.listdir(image_folder):\n",
        "#         image_path = os.path.join(image_folder, image_name)\n",
        "#         img = cv2.imread(image_path)\n",
        "#         text = pytesseract.image_to_string(img)\n",
        "\n",
        "#         text_data.append(text)\n",
        "#         image_paths.append(image_path)  # Store the image paths\n",
        "\n",
        "#     return text_data, image_paths  # Return the image paths instead of names\n",
        "\n",
        "# def create_autoencoder(input_dim, encoding_dim):\n",
        "#     # Define the encoder architecture\n",
        "#     input_layer = Input(shape=(input_dim,))\n",
        "#     encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "\n",
        "#     # Define the decoder architecture\n",
        "#     decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "#     # Create the autoencoder model\n",
        "#     autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "#     # Compile the autoencoder\n",
        "#     autoencoder.compile(optimizer='adam', loss='mse')  # Use Mean Squared Error as the loss function\n",
        "\n",
        "#     return autoencoder\n",
        "\n",
        "# def assign_labels_using_autoencoder(df, autoencoder, threshold):\n",
        "#     # Encode the text data using the trained autoencoder\n",
        "#     encoded_data = autoencoder.predict(df['Text Data'].str.len().values.reshape(-1, 1))\n",
        "\n",
        "#     # Calculate the reconstruction error (distance) for each data point\n",
        "#     reconstruction_error = np.mean(np.square(encoded_data - df['Text Data'].str.len().values.reshape(-1, 1)), axis=1)\n",
        "\n",
        "#     # Create a new column 'Label' based on the threshold\n",
        "#     df['Label'] = np.where(reconstruction_error > threshold, 'fraud', 'legitimate')\n",
        "\n",
        "#     return df\n",
        "\n",
        "# image_folder = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/images-dataset'\n",
        "\n",
        "# text_data, image_paths = extract_text_from_images(image_folder)\n",
        "\n",
        "# df = pd.DataFrame({'Image Path': image_paths, 'Text Data': text_data})\n",
        "\n",
        "# # Step 1: Preprocess the data (if needed)\n",
        "\n",
        "# # Step 2: Create the Autoencoder model\n",
        "# input_dim = 1  # Replace this with the actual size of your input data (1 because we are using text length)\n",
        "# encoding_dim = 64  # Choose an appropriate encoding dimension\n",
        "\n",
        "# autoencoder = create_autoencoder(input_dim, encoding_dim)\n",
        "\n",
        "# # Step 3: Train the Autoencoder\n",
        "# # Assuming you have preprocessed text data and stored it in 'X_train' variable\n",
        "# epochs = 50  # Replace with the desired number of epochs for training\n",
        "# batch_size = 32  # Replace with the desired batch size\n",
        "# autoencoder.fit(df['Text Data'].str.len().values.reshape(-1, 1),\n",
        "#                 df['Text Data'].str.len().values.reshape(-1, 1),\n",
        "#                 epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# # Step 4: Predict and Label the Data\n",
        "# # Assuming you have set an appropriate threshold\n",
        "# threshold = 0.1\n",
        "\n",
        "# df_labeled = assign_labels_using_autoencoder(df, autoencoder, threshold)\n",
        "\n",
        "# print(df_labeled)\n"
      ],
      "metadata": {
        "id": "FaD-PqHew-92"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_save_path = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/Dataset.csv'\n",
        "df.to_csv(csv_save_path, index=False)\n"
      ],
      "metadata": {
        "id": "GHJcpS8-xD5E"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # Assuming you have the OCR-extracted text data in a DataFrame 'df' with columns 'Image Path', 'Text Data', and 'Label'\n",
        "\n",
        "# # Data Cleaning and Preprocessing (if required)\n",
        "\n",
        "# # Feature Engineering: Using TF-IDF Vectorization\n",
        "# vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "# X = vectorizer.fit_transform(df['Text Data'])\n",
        "# y = df['Label']\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train the SVM classifier\n",
        "# model = SVC(kernel='linear')\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "# # Generate a classification report\n",
        "# print(\"Classification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "qCvcOt2jxICW"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # Assuming you have the OCR-extracted text data in a DataFrame 'df' with columns 'Image Path', 'Text Data', and 'Label'\n",
        "\n",
        "# # Data Cleaning and Preprocessing (if required)\n",
        "\n",
        "# # Feature Engineering: Using TF-IDF Vectorization\n",
        "# vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "# X = vectorizer.fit_transform(df['Text Data'])\n",
        "# y = df['Label']\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train the Random Forest classifier\n",
        "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy and print it in percentage\n",
        "# accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "# # Generate a classification report\n",
        "# print(\"Classification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "uO5QW-1axNFt"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Assuming you have the OCR-extracted text data in a DataFrame 'df' with columns 'Image Path', 'Text Data', and 'Label'\n",
        "\n",
        "# Data Cleaning and Preprocessing (if required)\n",
        "\n",
        "# Feature Engineering: Using TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "X = vectorizer.fit_transform(df['Text Data'])\n",
        "y = df['Label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy and print it in percentage\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nkLVJrI2xUP7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "3ac152d1-279b-436d-9eda-667d26943983"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.47%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.85        38\n",
            "           1       1.00      0.13      0.24        15\n",
            "\n",
            "    accuracy                           0.75        53\n",
            "   macro avg       0.87      0.57      0.54        53\n",
            "weighted avg       0.82      0.75      0.68        53\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
        "joblib.dump(model, 'train-model.joblib')"
      ],
      "metadata": {
        "id": "zFQoI9kjzU9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0065cd5f-8969-4c1d-e63b-5ba83bc2eef8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train-model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import xgboost as xgb\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # Assuming you have the OCR-extracted text data in a DataFrame 'df' with columns 'Image Path', 'Text Data', and 'Label'\n",
        "\n",
        "# # Data Cleaning and Preprocessing (if required)\n",
        "\n",
        "# # Feature Engineering: Using TF-IDF Vectorization\n",
        "# vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "# X = vectorizer.fit_transform(df['Text Data'])\n",
        "# y = df['Label']\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train the XGBoost classifier\n",
        "# model = xgb.XGBClassifier(random_state=42)\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy and print it in percentage\n",
        "# accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "# # Generate a classification report\n",
        "# print(\"Classification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "gLl_tHlvxXkN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # Assuming you have the OCR-extracted text data in a DataFrame 'df' with columns 'Image Path', 'Text Data', and 'Label'\n",
        "\n",
        "# # Data Cleaning and Preprocessing (if required)\n",
        "\n",
        "# # Feature Engineering: Using TF-IDF Vectorization\n",
        "# vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n",
        "# X = vectorizer.fit_transform(df['Text Data'])\n",
        "# y = df['Label']\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train the Naive Bayes classifier\n",
        "# model = MultinomialNB()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy and print it in percentage\n",
        "# accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "# # Generate a classification report\n",
        "# print(\"Classification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "-yJ_GfcYx0hf"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your CSV file is named 'dataset.csv' and located in the current working directory\n",
        "csv_file_path = '/content/drive/MyDrive/Colab Notebooks/Walmart Hackathon/Dataset.csv'\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Count the occurrences of each label in the 'Label' column\n",
        "label_counts = df['Label'].value_counts()\n",
        "\n",
        "# Print the number of fraud and legitimate records\n",
        "num_fraud_records = label_counts.get(0, 0)\n",
        "num_legitimate_records = label_counts.get(1, 0)\n",
        "\n",
        "print(\"Number of Fraud Records:\", num_fraud_records)\n",
        "print(\"Number of Legitimate Records:\", num_legitimate_records)\n"
      ],
      "metadata": {
        "id": "DPxYYyeIx3TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9124adc-120f-4bd6-c489-0f3cbd6d624d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Fraud Records: 109\n",
            "Number of Legitimate Records: 67\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}